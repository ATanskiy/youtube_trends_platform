version: "3.7"
services:

  # --------------------
  # Kafka & Confluent
  # --------------------
  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:7.5.0
    env_file:
      - envs/.env.zookeeper
    volumes:
      - ./volumes/.zookeeper/zk_data:/var/lib/zookeeper/data
      - ./volumes/.zookeeper/zk_logs:/var/lib/zookeeper/log
    ports:
      - "22181:2181"
    networks:
      - youtube_trends

  kafka_broker:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka_broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    env_file:
      - envs/.env.kafka
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka_broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
    volumes:
      - ./volumes/.kafka_data:/var/lib/kafka/data
    networks:
      - youtube_trends

  control_center:
    image: confluentinc/cp-enterprise-control-center:7.5.0
    container_name: control_center
    depends_on:
      - kafka_broker
      - zookeeper
    env_file:
      - envs/.env.control_center
    ports:
      - "9021:9021"
    networks:
      - youtube_trends

  # --------------------
  # Postgres, Hive Metastore 
  # --------------------
  pg_hive_db:
    image: 'postgres:17'
    hostname: postgres
    container_name: pg_hive_db
    ports:
      - '5434:5432'
    env_file:
      - envs/.env.pg_hive_db
    volumes:
      - ./volumes/.pg_hive_db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -p 5432 -U admin -d metastore_db"]
      interval: 5s
      timeout: 5s
      retries: 20
    networks:
      - youtube_trends

  hive_metastore:
    image: 'naushadh/hive-metastore'
    container_name: hive_metastore
    hostname: hive-metastore
    ports:
      - '9083:9083' # Metastore Thrift
    env_file:
      - envs/.env.pg_hive_db
    depends_on:
      pg_hive_db:
        condition: service_healthy
      minio:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/9083'"]
      interval: 5s
      timeout: 5s
      retries: 20
    networks:
      - youtube_trends

  # --------------------
  # Spark Streaming
  # --------------------
  spark_streaming:
    build:
      context: .
      dockerfile: ./docker/docker_files/Dockerfile.spark_streaming
    container_name: spark_streaming
    working_dir: /opt/streaming/jobs
    tmpfs:
      - /tmp:size=4G,exec
    ports:
      - "7077:7077" 
      - "4041:4040"    # Spark UI (different port)
    mem_limit: 8g
    mem_reservation: 6g
    volumes:
      - ./volumes/.spark_warehouse:/spark-warehouse
      - ./configs/spark_streaming/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
      - ./configs/spark_streaming/hive-site.xml:/opt/spark/conf/hive-site.xml
      - ./configs:/opt/streaming/configs
      - ./jobs:/opt/streaming/jobs
    env_file:
      - envs/.env.spark_streaming
    depends_on:
      - hive_metastore
      - kafka_broker
      - minio
    command: tail -f /dev/null
    networks:
      - youtube_trends
    restart: unless-stopped

  # --------------------
  # Airflow
  # --------------------
  pg_airflow_db:
    image: 'postgres:17'
    container_name: pg_airflow_db
    ports:
      - '5437:5432'
    env_file:
      - envs/.env.pg_airflow_db
    volumes:
      - ./volumes/.pg_airflow_db:/var/lib/postgresql/data
      - ./docker/scripts/airflow/airflow_db_init.sh:/docker-entrypoint-initdb.d/init-db.sh
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d airflow || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 15
    networks:
      - youtube_trends

  airflow-scheduler:
    image: apache/airflow:2.10.1-python3.11
    depends_on:
      pg_airflow_db:
        condition: service_healthy
    container_name: airflow_scheduler
    env_file:
      - envs/.env.airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./volumes/.airflow_logs:/opt/airflow/logs
      - ./jobs:/opt/airflow/jobs
      - ./docker/scripts/airflow/airflow_scheduler_entrypoint.sh:/opt/airflow/airflow_scheduler_entrypoint.sh
      - /var/run/docker.sock:/var/run/docker.sock
    healthcheck:
      test: ["CMD", "airflow", "jobs", "check", "--job-type", "SchedulerJob"]
      interval: 15s
      timeout: 5s
      retries: 5
    entrypoint: ["/opt/airflow/airflow_scheduler_entrypoint.sh"]
    networks:
      - youtube_trends

  airflow-webserver:
    image: apache/airflow:2.10.1-python3.11
    container_name: airflow_webserver
    depends_on:
      pg_airflow_db:
        condition: service_healthy
      airflow-scheduler:
        condition: service_healthy
    ports:
      - "8085:8080"
    env_file:
      - envs/.env.airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./volumes/.airflow_logs:/opt/airflow/logs
      - ./jobs:/opt/airflow/jobs
      - ./docker/scripts/airflow/airflow_webserver_entrypoint.sh:/opt/airflow/airflow_webserver_entrypoint.sh
      - /var/run/docker.sock:/var/run/docker.sock
    entrypoint: ["/opt/airflow/airflow_webserver_entrypoint.sh"]
    networks:
      - youtube_trends
    command: webserver

  # --------------------
  # MinIO
  # --------------------
  minio:
    image: minio/minio:RELEASE.2024-05-10T01-41-38Z
    hostname: minio
    container_name: minio
    ports:
      - '9000:9000'
      - '9001:9001'
    volumes:
      - ./volumes/.minio:/data
    env_file:
      - envs/.env.minio
    command: server --console-address ":9001" /data
    networks:
      - youtube_trends

  minio_init:
    image: minio/mc
    depends_on:
      - minio
    env_file:
      - envs/.env.minio
    entrypoint: ["/bin/sh", "/scripts/init.sh"]
    volumes:
    - ./docker/scripts/minio/minio_buckets_init.sh:/scripts/init.sh:ro
    networks:
      - youtube_trends

  trino:
    image: trinodb/trino:435
    container_name: trino
    hostname: trino
    ports:
      - "8080:8080"
    volumes:
      - ./configs/trino:/etc/trino
      - ./docker/scripts/trino:/opt/trino/sql
    environment:
      - GF_INSTALL_PLUGINS=grafana-trino-datasource
    env_file:
      - envs/.env.trino
    depends_on:
      - hive_metastore
      - minio
    networks:
      - youtube_trends
    user: "0"

    # Python container
  python_youtube_trends:
    build:
      context: .                  # root of your project
      dockerfile: docker/docker_files/Dockerfile.python_app
    container_name: python_youtube_trends
    working_dir: /app/youtube_trends_project
    environment:
      PYTHONPATH: /app/youtube_trends_project
    networks:
      - youtube_trends
    volumes:
      - .:/app
    env_file:
      - envs/.env.python_youtube_trends
    tty: true
    stdin_open: true

  # --------------------
  # Spark Thrift & DBT
  # --------------------
  spark_thriftserver:
    build:
      context: .
      dockerfile: ./docker/docker_files/Dockerfile.spark_thriftserver
    container_name:  spark-thriftserver
    hostname: spark-thriftserver
    ports:
      - "10000:10000"
      - "10001:10001"  # Thrift server for dbt JDBC
      - "4043:4040"    # Spark UI
    volumes:
      - ./configs/spark_thriftserver/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
      - ./configs/spark_iceberg/hive-site.xml:/opt/spark/conf/hive-site.xml
    env_file:
      - ./envs/.env.spark_thriftserver
    command: ["/start_thrift.sh"]
    depends_on:
      hive_metastore:
        condition: service_healthy
    networks:
      - youtube_trends

  dbt_spark_trino:
    build:
      context: .
      dockerfile: ./dbt_youtube_trends/Dockerfile.dbt_youtube_trends
    container_name: dbt_spark_trino
    volumes:
      - ./dbt_youtube_trends:/workspace
      - ./docs:/workspace/target
      - ./volumes/.dbt/dbt_logs:/workspace/logs
      - ./docker/scripts/dbt:/scripts
    environment:
      DBT_PROFILES_DIR: /workspace
    networks:
      - youtube_trends
    depends_on:
      - spark_thriftserver
    tty: true
    stdin_open: true

  pg_bi_db:
    image: postgres:17
    container_name: pg_bi_db
    hostname: pg-dbt
    ports:
      - "5438:5432"
    env_file:
      - envs/.env.pg_bi_db
    volumes:
      - ./volumes/.pg_bi_db:/var/lib/postgresql/data
      - ./docker/scripts/pg_bi/bi_init.sh:/docker-entrypoint-initdb.d/bi_init.sh
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d bi || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 15
    networks:
      - youtube_trends

  dbt_docs_server:
    image: nginx:alpine
    container_name: dbt_docs
    ports:
      - "8088:80"
    volumes:
      - ./docs:/usr/share/nginx/html:ro
    restart: unless-stopped

networks:
  youtube_trends:
    driver: bridge